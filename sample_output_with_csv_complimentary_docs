
# ==========================================
# FUNCTION-LOCAL VARIABLE TRACKER (V11.0)
# ==========================================
import datetime
import sys
import os
import builtins  
import csv
import types
import inspect

_AD_DEBUG_ACTIVE = True
_ORIGINAL_PRINT = builtins.print  

if not hasattr(builtins, '_PROJECT_BASELINE_VARS'):
    builtins._PROJECT_BASELINE_VARS = set(globals().keys()) | set(dir(builtins))

def _reset_logs():
    try:
        with open("_VARIABLE_TRACKER.csv", "w", encoding="utf-8", newline='') as f:
            writer = csv.writer(f, quoting=csv.QUOTE_ALL) # Force quoting on all fields
            writer.writerow(["File", "Line", "Variable", "Value"])
    except: pass

if not hasattr(builtins, '_AD_LOGS_WIPED'):
    _reset_logs()
    builtins._AD_LOGS_WIPED = True

def _record_state(file_path, line_no, local_vars):
    if not _AD_DEBUG_ACTIVE: return
    try:
        current_frame = inspect.currentframe().f_back
        if current_frame.f_code.co_name == '<module>':
            return

        baseline = getattr(builtins, '_PROJECT_BASELINE_VARS', set())

        with open("_VARIABLE_TRACKER.csv", "a", encoding="utf-8", newline='') as f:
            # Using QUOTE_ALL ensures that even numbers are wrapped in "", 
            # preventing Column E overflow.
            writer = csv.writer(f, quoting=csv.QUOTE_ALL)

            for var_name, var_val in local_vars.items():
                if var_name.startswith('_') or var_name in baseline: 
                    continue 

                if isinstance(var_val, (type, types.FunctionType, types.ModuleType, types.MethodType)):
                    continue

                # --- ADVANCED SANITIZATION FOR COLUMN E OVERFLOW ---
                # Convert to string and replace literal newlines/carriages
                val_str = str(var_val).replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')

                # Remove brackets and quotes which are the primary cause of the "None]" artifact
                # This ensures the data cannot be misinterpreted as a multi-column array.
                sanitized_val = val_str.replace("'", "").replace("[", "").replace("]", "").strip()

                if not sanitized_val:
                    sanitized_val = "None"

                # Construct the rigid 4-column row
                row = [
                    os.path.basename(file_path),
                    line_no,
                    var_name,
                    sanitized_val
                ]

                writer.writerow(row)
    except: pass

def _ad_script_output(msg, is_error=True):
    if not _AD_DEBUG_ACTIVE: return
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    formatted = f"[DEBUG_ERROR] [{timestamp}] {msg}" if is_error else f"[SCRIPT] {msg}"
    _ORIGINAL_PRINT(formatted)
    for f_name in ["_DEBUG_ONLY.txt", "_COMBINED_LOG.txt"] if is_error else ["_SCRIPT_ONLY.txt", "_COMBINED_LOG.txt"]:
        try:
            with open(f_name, "a", encoding="utf-8") as f: f.write(formatted + "\n")
        except: pass

def print(*args, **kwargs):
    output = " ".join(map(str, args))
    _ad_script_output(output, is_error=False)
# ==========================================

import time
import urllib.request
import sys
import os
import csv
from collections import Counter


def find_strict_anagrams(user_input, max_words=5, split_limit=29999):
    
    try:
        print("[1/3] Loading Resources...")
        _record_state(__file__, 11, locals())
    except Exception as e:
        _ad_script_output(f'Line 11 Failed: {e}', is_error=True)

    try:
        blacklist_file = "blacklist.csv"
        _record_state(__file__, 13, locals())
    except Exception as e:
        _ad_script_output(f'Line 13 Failed: {e}', is_error=True)
    try:
        blacklist = set()
        _record_state(__file__, 14, locals())
    except Exception as e:
        _ad_script_output(f'Line 14 Failed: {e}', is_error=True)
    try:
        default_blacklist = ['ca', 'ny', 'tx', 'fl', 'wa', 'al', 'ok', 'id', 'oh', 'or', 'la', 'ncaa']
        _record_state(__file__, 15, locals())
    except Exception as e:
        _ad_script_output(f'Line 15 Failed: {e}', is_error=True)

    
    if not os.path.exists(blacklist_file):
        try:
            with open(blacklist_file, "w", newline='') as f:
                try:
                    writer = csv.writer(f)
                    _record_state(__file__, 21, locals())
                except Exception as e:
                    _ad_script_output(f'Line 21 Failed: {e}', is_error=True)
                try:
                    writer.writerow(["Category", "Uniques"])
                    _record_state(__file__, 22, locals())
                except Exception as e:
                    _ad_script_output(f'Line 22 Failed: {e}', is_error=True)
                for word in default_blacklist:
                    try:
                        writer.writerow(["Default", word])
                        _record_state(__file__, 24, locals())
                    except Exception as e:
                        _ad_script_output(f'Line 24 Failed: {e}', is_error=True)
            try:
                blacklist = set(default_blacklist)
                _record_state(__file__, 25, locals())
            except Exception as e:
                _ad_script_output(f'Line 25 Failed: {e}', is_error=True)
        except Exception as e:
            try:
                print(f"   > Error creating CSV: {e}")
                _record_state(__file__, 27, locals())
            except Exception as e:
                _ad_script_output(f'Line 27 Failed: {e}', is_error=True)
    else:
        try:
            with open(blacklist_file, "r", newline='') as f:
                try:
                    reader = csv.DictReader(f)
                    _record_state(__file__, 31, locals())
                except Exception as e:
                    _ad_script_output(f'Line 31 Failed: {e}', is_error=True)
                if reader.fieldnames and 'Uniques' in reader.fieldnames:
                    for row in reader:
                        try:
                            val = row.get('Uniques', '').strip().lower()
                            _record_state(__file__, 34, locals())
                        except Exception as e:
                            _ad_script_output(f'Line 34 Failed: {e}', is_error=True)
                        if val: blacklist.add(val)
        except Exception as e:
            try:
                print(f"   > Error reading CSV: {e}")
                _record_state(__file__, 37, locals())
            except Exception as e:
                _ad_script_output(f'Line 37 Failed: {e}', is_error=True)

    
    try:
        url = "https://raw.githubusercontent.com/first20hours/google-10000-english/master/google-10000-english-no-swears.txt"
        _record_state(__file__, 40, locals())
    except Exception as e:
        _ad_script_output(f'Line 40 Failed: {e}', is_error=True)
    try:
        with urllib.request.urlopen(url) as response:
            try:
                raw_words = response.read().decode('utf-8').splitlines()
                _record_state(__file__, 43, locals())
            except Exception as e:
                _ad_script_output(f'Line 43 Failed: {e}', is_error=True)
    except Exception as e:
        try:
            print(f"Error fetching dictionary: {e}")
            _record_state(__file__, 45, locals())
        except Exception as e:
            _ad_script_output(f'Line 45 Failed: {e}', is_error=True)
        try:
            return
            _record_state(__file__, 46, locals())
        except Exception as e:
            _ad_script_output(f'Line 46 Failed: {e}', is_error=True)

    
    try:
        clean_target = "".join(filter(str.isalpha, user_input.lower()))
        _record_state(__file__, 49, locals())
    except Exception as e:
        _ad_script_output(f'Line 49 Failed: {e}', is_error=True)
    try:
        target_count = Counter(clean_target)
        _record_state(__file__, 50, locals())
    except Exception as e:
        _ad_script_output(f'Line 50 Failed: {e}', is_error=True)

    try:
        candidates = []
        _record_state(__file__, 52, locals())
    except Exception as e:
        _ad_script_output(f'Line 52 Failed: {e}', is_error=True)
    for word in raw_words:
        try:
            w = word.lower()
            _record_state(__file__, 54, locals())
        except Exception as e:
            _ad_script_output(f'Line 54 Failed: {e}', is_error=True)
        if (len(w) < 3 and w not in ['a', 'i']) or w in blacklist:
            try:
                continue
                _record_state(__file__, 56, locals())
            except Exception as e:
                _ad_script_output(f'Line 56 Failed: {e}', is_error=True)
        try:
            w_count = Counter(w)
            _record_state(__file__, 57, locals())
        except Exception as e:
            _ad_script_output(f'Line 57 Failed: {e}', is_error=True)
        if all(w_count[c] <= target_count[c] for c in w_count):
            try:
                candidates.append(w)
                _record_state(__file__, 59, locals())
            except Exception as e:
                _ad_script_output(f'Line 59 Failed: {e}', is_error=True)
    try:
        candidates.sort(key=len, reverse=True)
        _record_state(__file__, 60, locals())
    except Exception as e:
        _ad_script_output(f'Line 60 Failed: {e}', is_error=True)

    
    try:
        print(f"[2/3] Searching for phrases in '{user_input}'...")
        _record_state(__file__, 63, locals())
    except Exception as e:
        _ad_script_output(f'Line 63 Failed: {e}', is_error=True)

    try:
        found_hashes = set()
        _record_state(__file__, 65, locals())
    except Exception as e:
        _ad_script_output(f'Line 65 Failed: {e}', is_error=True)
    try:
        matches = 0
        _record_state(__file__, 66, locals())
    except Exception as e:
        _ad_script_output(f'Line 66 Failed: {e}', is_error=True)
    try:
        file_index = 1
        _record_state(__file__, 67, locals())
    except Exception as e:
        _ad_script_output(f'Line 67 Failed: {e}', is_error=True)
    try:
        current_entries = 0
        _record_state(__file__, 68, locals())
    except Exception as e:
        _ad_script_output(f'Line 68 Failed: {e}', is_error=True)
    try:
        current_part_file = None
        _record_state(__file__, 69, locals())
    except Exception as e:
        _ad_script_output(f'Line 69 Failed: {e}', is_error=True)

    
    try:
        safe_name = "".join(x for x in user_input if x.isalnum())[:15]
        _record_state(__file__, 72, locals())
    except Exception as e:
        _ad_script_output(f'Line 72 Failed: {e}', is_error=True)
    try:
        master_filename = f"MASTER_list_{safe_name}_{str(time.time())}.txt"
        _record_state(__file__, 73, locals())
    except Exception as e:
        _ad_script_output(f'Line 73 Failed: {e}', is_error=True)
    try:
        master_file = open(master_filename, "w")
        _record_state(__file__, 74, locals())
    except Exception as e:
        _ad_script_output(f'Line 74 Failed: {e}', is_error=True)
    master_file.write("[")  

    def get_part_file():
        nonlocal current_part_file, file_index, current_entries
        if current_part_file is None or current_entries >= split_limit:
            if current_part_file: current_part_file.close()
            fname = f"anagram_res_{safe_name}_{str(time.time())}_{file_index}.txt"
            current_part_file = open(fname, "w")
            file_index += 1
            current_entries = 0
        return current_part_file

    def backtrack(path, pool):
        nonlocal matches, current_entries
        if sum(pool.values()) == 0:
            phrase_hash = tuple(sorted(path))
            if phrase_hash not in found_hashes:
                phrase_str = " ".join(path).title()

                
                if matches > 0:
                    master_file.write(", ")
                master_file.write(phrase_str)

                
                get_part_file().write(phrase_str + "\n")

                found_hashes.add(phrase_hash)
                matches += 1
                current_entries += 1

                if matches % 100 == 0:
                    sys.stdout.write(f'\râœ¨ Found {matches}...')
                    sys.stdout.flush()
            return

        if len(path) >= max_words: return
        for word in candidates:
            if len(word) > sum(pool.values()): continue
            w_count = Counter(word)
            if all(pool[c] >= w_count[c] for c in w_count):
                backtrack(path + [word], pool - w_count)

    
    for i, root in enumerate(candidates):
        sys.stdout.write(f'\rProgress: {(i / len(candidates)) * 100:.1f}% ')
        backtrack([root], target_count - Counter(root))

    
    master_file.write("}")  
    try:
        master_file.close()
        _record_state(__file__, 125, locals())
    except Exception as e:
        _ad_script_output(f'Line 125 Failed: {e}', is_error=True)
    if current_part_file: current_part_file.close()

    try:
        print(f"\n[3/3] Done!")
        _record_state(__file__, 128, locals())
    except Exception as e:
        _ad_script_output(f'Line 128 Failed: {e}', is_error=True)
    try:
        print(f" > Standard parts created: {file_index - 1} file(s)")
        _record_state(__file__, 129, locals())
    except Exception as e:
        _ad_script_output(f'Line 129 Failed: {e}', is_error=True)
    try:
        print(f" > Master comma-list created: {master_filename}")
        _record_state(__file__, 130, locals())
    except Exception as e:
        _ad_script_output(f'Line 130 Failed: {e}', is_error=True)



try:
    u_in = input("Enter phrase: ")
    _record_state(__file__, 134, locals())
except Exception as e:
    _ad_script_output(f'Line 134 Failed: {e}', is_error=True)
try:
    find_strict_anagrams(u_in)
    _record_state(__file__, 135, locals())
except Exception as e:
    _ad_script_output(f'Line 135 Failed: {e}', is_error=True)
